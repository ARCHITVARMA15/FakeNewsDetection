import pickle
import pandas as pd
import re
from statistics import mode
import requests 

print("ğŸš€ predict_test.py started running...")


def get_confidence_meter(score):
    """
    Returns a visual emoji-based confidence bar and label.
    Score is between 0 and 1.
    """
    if score >= 0.9:
        bar = "ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©  (Very High Confidence)"
    elif score >= 0.75:
        bar = "ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ¨â¬œ  (High Confidence)"
    elif score >= 0.5:
        bar = "ğŸŸ©ğŸŸ¨â¬œâ¬œâ¬œ  (Moderate Confidence)"
    else:
        bar = "ğŸŸ¥â¬œâ¬œâ¬œâ¬œ  (Low Confidence)"
    return bar



# ==========================================
# 1ï¸âƒ£ Load Trained Models & Vectorizer
# ==========================================
LR = pickle.load(open("model_lr.pkl", "rb"))
rfc = pickle.load(open("model_rfc.pkl", "rb"))
gbc = pickle.load(open("model_gbc.pkl", "rb"))
vectorizer = pickle.load(open("vectorizer.pkl", "rb"))

print("âœ… Models and vectorizer loaded successfully!")

# ==========================================
# 2ï¸âƒ£ Text Cleaning Function (Same as Training)
# ==========================================
def wordopt(text):
    text = text.lower()
    text = re.sub(r'https?://\S+|www\.\S+', '', text)
    text = re.sub(r'<.*?>', '', text)
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\d', '', text)
    text = re.sub(r'\n', '', text)
    return text

# ==========================================
# 3ï¸âƒ£ Output Label Helper
# ==========================================
def output_label(n):
    return "It is a Fake News âŒ" if n == 0 else "It is a Genuine News âœ…"




def verify_with_api(news_text):
    """
    Uses NewsData.io API to check if similar verified news exists online.
    """
    API_KEY = "pub_024f49ef2b7341ee9e0a81d70795132a"
    url = f"https://newsdata.io/api/1/news?apikey={API_KEY}&q={requests.utils.quote(news_text)}&language=en"

    try:
        response = requests.get(url)
        data = response.json()

        if data.get("status") == "success" and len(data.get("results", [])) > 0:
            source_titles = [item['title'] for item in data['results'][:3]]
            print("\nğŸŒ Verified sources found online:")
            for title in source_titles:
                print("ğŸ“°", title)
            return 1  # Genuine
        else:
            print("\nâš ï¸ No verified articles found online.")
            return 0  # Fake

    except Exception as e:
        print(f"ğŸš¨ API Error: {e}")
        return -1


def verify_with_google_factcheck(news_text):
    """
    Uses Google Fact Check API to verify claims.
    Returns:
      1 = Genuine / Verified True
      0 = Fake / Misleading
     -1 = API Error or No data
    """
    GOOGLE_API_KEY = "AIzaSyDHc6fLAnaDwuoxVFjSNe-E_yvYkUdL2Fw"
    base_url = f"https://factchecktools.googleapis.com/v1alpha1/claims:search?key={GOOGLE_API_KEY}"
    params = {
        "query": news_text,
        "languageCode": "en"
    }

    try:
        response = requests.get(base_url, params=params)
        data = response.json()

        if "claims" in data:
            claims = data["claims"]
            print("\nğŸ” Google Fact Check Results Found:")
            for c in claims[:3]:
                text = c.get("text", "")
                publisher = c.get("claimReview", [{}])[0].get("publisher", {}).get("name", "")
                rating = c.get("claimReview", [{}])[0].get("textualRating", "Unknown")
                print(f"ğŸ“° {text}\n   Source: {publisher} | Rating: {rating}\n")

            ratings = [r.get("claimReview", [{}])[0].get("textualRating", "").lower() for r in claims]
            if any("false" in r or "fake" in r or "incorrect" in r for r in ratings):
                return 0
            elif any("true" in r or "accurate" in r for r in ratings):
                return 1
            else:
                return -1
        else:
            print("\nâš ï¸ No fact-checking data found for this claim.")
            return -1

    except Exception as e:
        print(f"ğŸš¨ Google Fact Check API Error: {e}")
        return -1


# ==========================================
# 4ï¸âƒ£ Manual Testing Function (with Majority Vote)
# ==========================================
# def manual_testing(news_text):
#     """
#     Cleans and vectorizes the given news text,
#     predicts using LR, RFC, GBC,
#     and gives a final majority-vote result.
#     """
#     # Create DataFrame
#     testing_news = {"text": [news_text]}
#     new_df_test = pd.DataFrame(testing_news)

#     # Apply same preprocessing
#     new_df_test['text'] = new_df_test['text'].apply(wordopt)

#     # Transform using the saved TF-IDF vectorizer
#     new_xv_test = vectorizer.transform(new_df_test['text'])

#     # Individual model predictions
#     pred_lr = LR.predict(new_xv_test)[0]
#     rfc_pred = rfc.predict(new_xv_test)[0]
#     gbc_pred = gbc.predict(new_xv_test)[0]

#     # Majority vote (mode)
#     final_pred = mode([pred_lr, rfc_pred, gbc_pred])

#     # Confidence (from Random Forest)
#     prob = round(float(rfc.predict_proba(new_xv_test).max()), 2)

#     #API Verification
#     api_verdict = verify_with_api(news_text)

#     #combine both sources of truth 
#     if api_verdict == -1:
#         final_verdict = final_pred
#     elif api_verdict != final_pred:
#         final_verdict = api_verdict 
#     else:
#         final_verdict = final_pred

#     # Output formatting
#     result = f"""
# ğŸ” Model Predictions:
# ---------------------------------------------
# ğŸ”¹ Logistic Regression: {output_label(pred_lr)}
# ğŸ”¹ Random Forest:       {output_label(rfc_pred)}
# ğŸ”¹ Gradient Boosting:   {output_label(gbc_pred)}
# ---------------------------------------------
# ğŸŸ© Final Verdict (Majority Vote): {output_label(final_pred)}
# ğŸ“Š Confidence (from RFC): {prob}

# ğŸŒ API Verification Result: {output_label(api_verdict)}
# âœ… Final Decision (Model+ API):{output_label(final_verdict)}
# """
#     return result




from statistics import mode

def manual_testing(news_text):
    """
    Performs fake news verification using:
      - 3 ML models (LR, RFC, GBC)
      - NewsData.io API
      - Google Fact Check API

    Returns final result based on:
      Priority: Google Fact Check > NewsData.io > ML Majority
    """

    print("\nğŸ” Starting full verification process...\n")

    # ğŸ§¹ Step 1: Clean and vectorize input text
    testing_news = {"text": [news_text]}
    new_df_test = pd.DataFrame(testing_news)
    new_df_test['text'] = new_df_test['text'].apply(wordopt)
    new_xv_test = vectorizer.transform(new_df_test['text'])

    # ğŸ¤– Step 2: ML model predictions
    pred_lr = LR.predict(new_xv_test)[0]
    pred_rfc = rfc.predict(new_xv_test)[0]
    pred_gbc = gbc.predict(new_xv_test)[0]

    print("----------------------------------------------------")
    print("ğŸ¤– ML Model Predictions:")
    print("----------------------------------------------------")
    print(f"ğŸ”¹ Logistic Regression: {output_label(pred_lr)}")
    print(f"ğŸ”¹ Random Forest:       {output_label(pred_rfc)}")
    print(f"ğŸ”¹ Gradient Boosting:   {output_label(pred_gbc)}")

    model_predictions = [pred_lr, pred_rfc, pred_gbc]
    model_majority = mode(model_predictions)
    confidence = round(float(rfc.predict_proba(new_xv_test).max()), 2)


    confidence_bar = get_confidence_meter(confidence)
    print(f"ğŸ“Š Confidence (RFC): {confidence}  {confidence_bar}")


    print(f"\nğŸŸ© ML Majority Verdict: {output_label(model_majority)}")
    print(f"ğŸ“Š Confidence (RFC): {confidence}")

    # ğŸŒ Step 3: API Verifications
    print("\n----------------------------------------------------")
    print("ğŸŒ Checking with NewsData.io API...")
    newsio_result = verify_with_api(news_text)
    print("----------------------------------------------------")
    print("ğŸ” Checking with Google Fact Check API...")
    google_result = verify_with_google_factcheck(news_text)

    # ğŸ§® Step 4: Final Decision Logic
    print("\n----------------------------------------------------")
    print("ğŸ§  Final Decision Logic:")
    print("----------------------------------------------------")

    if google_result in [0, 1]:
        final_result = google_result
        final_source = "Google Fact Check API"
    elif newsio_result in [0, 1]:
        final_result = newsio_result
        final_source = "NewsData.io API"
    else:
        final_result = model_majority
        final_source = "ML Ensemble (Majority Vote)"

    # ğŸ§¾ Step 5: Print Summary
    print(f"\nğŸŒ NewsData.io API Result: {output_label(newsio_result)}")
    print(f"ğŸ” Google Fact Check Result: {output_label(google_result)}")
    print("----------------------------------------------------")
    print(f"âœ… Final Decision (Based on {final_source}): {output_label(final_result)}")
    print("----------------------------------------------------")
    print("ğŸŸ¢ Verification completed successfully!\n")

    return final_result


# ==========================================
# 5ï¸âƒ£ Run Manual Testing
# ==========================================
if __name__ == "__main__":
    print("----------------------------------------------------")
    news_article = str(input("ğŸ“° Enter the news article text:\n"))
    print("----------------------------------------------------")
    print(manual_testing(news_article))
    print("----------------------------------------------------")
    print("âœ… Verification completed successfully!")